{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Intelligent Agents with DeepSeek R1, CrewAI and SageMaker\n",
    "\n",
    "This notebook demonstrates how to build and deploy an intelligent agent system using DeepSeek R1 (Distilled), CrewAI and Amazon SageMaker. We'll create a multi-agent system called ScribbleBots that can perform research and writing tasks using state-of-the-art language models.\n",
    "\n",
    "## Overview\n",
    "1. Set up the development environment\n",
    "2. Deploy DeepSeek R1 LLaMA 3.3 70B model on SageMaker\n",
    "3. Create intelligent agents using CrewAI\n",
    "4. Implement a sequential workflow for research and writing tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- AWS Account with SageMaker access\n",
    "- Hugging Face account and API token\n",
    "- Python 3.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "First, let's install the required dependencies. We'll need CrewAI for agent orchestration, boto3 for AWS interactions, and various ML-related packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU crewai boto3 sagemaker \"streamlit==1.38.0\" huggingface_hub psutil pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade transformers==4.44.2 torch>=1.1.13 torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Environment Variables\n",
    "\n",
    "Set up the necessary credentials and configuration for AWS and Hugging Face. Make sure to replace the empty strings with your actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration Variables\n",
    "bucket_name = \"\"  # Your S3 bucket name\n",
    "HUGGING_FACE_HUB_TOKEN = \"\"  # Your Hugging Face token\n",
    "my_region_name = \"\"  # Your AWS region (e.g., \"us-east-1\")\n",
    "\n",
    "# Validation\n",
    "assert bucket_name != \"\", \"Please provide Bucket name above\"\n",
    "assert HUGGING_FACE_HUB_TOKEN != \"\", \"Please provide Huggingface token above\"\n",
    "assert my_region_name != \"\", \"Please provide a region above\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Deploy and Predict Using DeepSeek R1 Distilled Model on SageMaker\n",
    "\n",
    "We'll deploy the DeepSeek R1 Distilled LLaMA 3.3 70B model on SageMaker. This model will serve as our primary language model for the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure AWS and SageMaker\n",
    "number_of_gpu = 8\n",
    "boto_session = boto3.Session(region_name=my_region_name)\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session, default_bucket=bucket_name)\n",
    "\n",
    "# Get or create IAM role\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Model configuration\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'deepseek-ai/DeepSeek-R1-Distill-Llama-70B', #Llama-3.3-70B-Instruct\n",
    "\t'SM_NUM_GPUS': json.dumps(number_of_gpu),\n",
    "    'HF_TOKEN': HUGGING_FACE_HUB_TOKEN,\n",
    "    'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',  # Set to INFO level\n",
    "    'PYTORCH_CUDA_ALLOC_CONF': 'expandable_segments:True'  # Add this line\n",
    "}\n",
    "\n",
    "\n",
    "# Create endpoint name\n",
    "custom_endpoint_name = f'deepseek-r1-dist-v3-llama70b-{datetime.now().strftime(\"%Y-%m-%d\")}'\n",
    "\n",
    "# Create and deploy model\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    image_uri=get_huggingface_llm_image_uri(\"huggingface\", version=\"2.3.1\"),\n",
    "    env=hub,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    endpoint_name=custom_endpoint_name,\n",
    "    container_startup_health_check_timeout=900\n",
    ")\n",
    "\n",
    "# Test the endpoint\n",
    "response = predictor.predict({\n",
    "    \"inputs\": \"Hi, what can you help me with?\"\n",
    "})\n",
    "print(\"Test response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create ScribbleBots - An Agentic Research Writer\n",
    "\n",
    "Now we'll create a multi-agent system consisting of a Research Agent and a Writer Agent. These agents will work together in a sequential workflow to research topics and create high-quality written content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Crew, Agent, Task, Process\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from tools.sage_tools import CustomTool, deepseek_llama_inference, DeepSeekSageMakerLLM\n",
    "\n",
    "\n",
    "# Create DeepSeek inference tool\n",
    "deepseek_tool = CustomTool(\n",
    "    name=\"deepseek_llama_3.3_70B\",\n",
    "    func=lambda inputs: deepseek_llama_inference(\n",
    "        prompt=inputs,\n",
    "        endpoint_name=custom_endpoint_name\n",
    "    ),\n",
    "    description=\"A tool to generate text using the DeepSeek LLaMA model deployed on SageMaker.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Note\n",
    "\n",
    "If you see this error, please diregard it\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/error.png\" alt=\"workflow diagram\" style=\"border: 5px solid black; padding: 10px; box-shadow: 5px 5px 5px grey;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Research Agent\n",
    "\n",
    "The Research Agent is responsible for gathering and analyzing information from various sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = Agent(\n",
    "    role=\"Research Bot\",\n",
    "    goal=\"Scan sources, extract relevant information, and compile a research summary.\",\n",
    "    backstory=\"An AI agent skilled in finding relevant information from a variety of sources.\",\n",
    "    tools=[deepseek_tool],\n",
    "    allow_delegation=True,\n",
    "    llm=DeepSeekSageMakerLLM(endpoint=custom_endpoint_name),\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Writer Agent\n",
    "\n",
    "The Writer Agent transforms research findings into polished, structured content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    role=\"Writer Bot\",\n",
    "    goal=\"Receive research summaries and transform them into structured content.\",\n",
    "    backstory=\"A talented writer bot capable of producing high-quality, structured content based on research.\",\n",
    "    tools=[deepseek_tool],\n",
    "    allow_delegation=False,\n",
    "    llm=DeepSeekSageMakerLLM(endpoint=custom_endpoint_name),\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agent Tasks\n",
    "\n",
    "Set up the specific tasks for each agent in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Your task is to conduct research based on the following query: {prompt}.\\n\"\n",
    "        \"- Scan multiple sources to gather relevant information.\\n\"\n",
    "        \"- Summarize your findings into a concise, well-organized research summary.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive research summary based on the provided query.\",\n",
    "    agent=research_agent,\n",
    "    tools=[deepseek_tool]\n",
    ")\n",
    "\n",
    "writing_task = Task(\n",
    "    description=(\n",
    "        \"Your task is to create structured content based on the research provided.\\n\"\n",
    "        \"- Transform the research into high-quality written content.\\n\"\n",
    "        \"- Ensure the output is clear, organized, and adheres to professional writing standards.\\n\"\n",
    "        \"- Focus on maintaining the key points while improving readability and flow.\"\n",
    "    ),\n",
    "    expected_output=\"A well-structured article based on the research summary.\",\n",
    "    agent=writer_agent,\n",
    "    tools=[deepseek_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Execute the Crew\n",
    "\n",
    "Finally, we'll create the crew with our agents and tasks, then execute a test workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agents with CrewAI and SageMaker\n",
    "\n",
    "## Execute Research Workflow\n",
    "Now we'll execute our research and writing workflow with the configured agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble_bots = Crew(\n",
    "    agents=[research_agent, writer_agent],\n",
    "    tasks=[research_task, writing_task],\n",
    "    process=Process.sequential  # Ensure tasks execute in sequence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(raw_text):\n",
    "    \"\"\"Format the raw response text for better readability\"\"\"\n",
    "    formatted_text = raw_text.replace('\\\\n', '\\n').strip()\n",
    "    return formatted_text\n",
    "\n",
    "def parse_agent_response(response):\n",
    "    \"\"\"Helper function to parse and structure agent responses\"\"\"\n",
    "    thought = \"Could not extract Chain of Thought.\"\n",
    "    answer = \"Could not extract Final Answer.\"\n",
    "    \n",
    "    try:\n",
    "        if isinstance(response, str):\n",
    "            response = format_response(response)\n",
    "            \n",
    "            if \"Thought:\" in response:\n",
    "                thought_start = response.find(\"Thought:\") + len(\"Thought:\")\n",
    "                thought_end = response.find(\"'Final Answer':\") if \"'Final Answer':\" in response else len(response)\n",
    "                thought = response[thought_start:thought_end].strip()\n",
    "            \n",
    "            if \"'Final Answer':\" in response:\n",
    "                answer_start = response.find(\"'Final Answer':\") + len(\"'Final Answer':\")\n",
    "                answer = response[answer_start:].strip()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        \n",
    "    return thought, answer\n",
    "\n",
    "# Execute the workflow\n",
    "print(\"Starting ScribbleBots Sequential Workflow...\")\n",
    "result = scribble_bots.kickoff(inputs={\"prompt\": \"Explain what is deepseek very briefly\"})\n",
    "\n",
    "# Parse and display results\n",
    "if hasattr(result, 'raw') and isinstance(result.raw, dict):\n",
    "    raw_response = result.raw\n",
    "    if isinstance(raw_response, list) and \"generated_text\" in raw_response[0]:\n",
    "        thought, answer = parse_agent_response(raw_response[0][\"generated_text\"])\n",
    "    else:\n",
    "        thought, answer = parse_agent_response(str(raw_response))\n",
    "else:\n",
    "    thought, answer = parse_agent_response(str(result))\n",
    "\n",
    "# Display parsed outputs\n",
    "print(\"***************************************\")\n",
    "print(\"\\n=== Chain of Thought ===\")\n",
    "print(\"***************************************\")\n",
    "print(thought)\n",
    "print(\"***************************************\")\n",
    "print(\"***************************************\")\n",
    "print(\"\\n=== Final Answer ===\")\n",
    "print(answer)\n",
    "print(\"***************************************\")\n",
    "print(\"***************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
