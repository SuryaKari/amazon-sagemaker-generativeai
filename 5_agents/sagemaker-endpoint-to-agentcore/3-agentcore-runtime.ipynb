{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Querying an ML Model on an Amazon SageMaker AI Endpoint with an MCP Server hosted on Amazon Bedrock AgentCore Runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will learn how to host MCP (Model Context Protocol) servers on Amazon Bedrock AgentCore Runtime. We will use the Amazon Bedrock AgentCore Python SDK to wrap MCP tools as an MCP server compatible with Amazon Bedrock AgentCore.\n",
    "\n",
    "The Amazon Bedrock AgentCore Python SDK handles the MCP server implementation details so you can focus on your tools' core functionality. It transforms your code into the AgentCore standardized MCP protocol contracts for direct communication.\n",
    "\n",
    "In this example, we will create an MCP Server\n",
    "\n",
    "### Tutorial Key Features\n",
    "\n",
    "* Creating MCP servers that communicates with the SageMaker AI Endpoint\n",
    "* Testing MCP servers locally\n",
    "* Hosting MCP servers on Amazon Bedrock AgentCore Runtime\n",
    "* Invoking deployed MCP servers with authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install-r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce707ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## Understanding MCP (Model Context Protocol)\n",
    "\n",
    "MCP is a protocol that allows AI models to securely access external data and tools. Key concepts:\n",
    "\n",
    "* **Tools**: Functions that the AI can call to perform actions\n",
    "* **Streamable HTTP**: Transport protocol used by AgentCore Runtime\n",
    "* **Session Isolation**: Each client gets isolated sessions via `Mcp-Session-Id` header\n",
    "* **Stateless Operation**: Servers must support stateless operation for scalability\n",
    "\n",
    "AgentCore Runtime expects MCP servers to be hosted on `0.0.0.0:8000/mcp` as the default path.\n",
    "\n",
    "### Project Structure\n",
    "\n",
    "Let's set up our project with the proper structure:\n",
    "\n",
    "```\n",
    "mcp_server_project/\n",
    "├── mcp_server.py              # Main MCP server code\n",
    "├── my_mcp_client.py          # Local testing client\n",
    "├── my_mcp_client_remote.py   # Remote testing client\n",
    "├── requirements.txt          # Dependencies\n",
    "└── __init__.py              # Python package marker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2_create_server",
   "metadata": {},
   "source": [
    "## Creating MCP Server\n",
    "\n",
    "Now let's create our MCP server with three simple tools. The server uses FastMCP with `stateless_http=True` which is required for AgentCore Runtime compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d386ab54e85e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mcp_server.py\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from starlette.responses import JSONResponse\n",
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "mcp = FastMCP(host=\"0.0.0.0\", stateless_http=True)\n",
    "\n",
    "@mcp.tool()\n",
    "def demand_forecasting_with_ml(sample_data):\n",
    "\t\"\"\"\n",
    "\tThis tool predicts future demand based on historical data using a machine learning model.\n",
    "\t\"\"\"\n",
    "\tsagemaker_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\tendpoint_name = \"ml-models-as-tools\"\n",
    "\tresponse = sagemaker_runtime.invoke_endpoint(\n",
    "\t\tEndpointName=endpoint_name,\n",
    "\t\tBody=json.dumps(sample_data),\n",
    "\t\tContentType=\"application/json\",\n",
    "\t\tAccept=\"application/json\"\n",
    "\t)\n",
    "\tpredictions = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "\treturn np.array(predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understand_code",
   "metadata": {},
   "source": [
    "### What This Code Does\n",
    "\n",
    "* **FastMCP**: Creates an MCP server that can host your tools\n",
    "* **@mcp.tool()**: Decorator that turns your Python functions into MCP tools\n",
    "* **stateless_http=True**: Required for AgentCore Runtime compatibility\n",
    "* **Tools**: Three simple tools demonstrating different types of operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3_local_client",
   "metadata": {},
   "source": [
    "## Creating Local Testing Client\n",
    "\n",
    "To test your MCP server locally:\n",
    "\n",
    "1. **Terminal 1**: Start the MCP server\n",
    "   ```bash\n",
    "   python mcp_server.py\n",
    "   ```\n",
    "   \n",
    "2. Run the agent in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53423c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = [[6.0,\n",
    "  9.0,\n",
    "  18.0,\n",
    "  2022.0,\n",
    "  3.0,\n",
    "  82.32242989519233,\n",
    "  145.7780143415423,\n",
    "  119.72411707626237,\n",
    "  109.00943866750897,\n",
    "  78.1850279953027,\n",
    "  27.17729231087614,\n",
    "  98.725083103897,\n",
    "  32.3663008574393,\n",
    "  114.30045179438677,\n",
    "  31.154757059649896],\n",
    " [0.0,\n",
    "  9.0,\n",
    "  19.0,\n",
    "  2022.0,\n",
    "  3.0,\n",
    "  112.29372828348961,\n",
    "  92.05548651574294,\n",
    "  149.53457153115409,\n",
    "  72.54645882732314,\n",
    "  78.59649696115221,\n",
    "  27.4428007288024,\n",
    "  94.82516865714953,\n",
    "  28.874170960965433,\n",
    "  115.04676214269898,\n",
    "  30.378550374126004],\n",
    " [1.0,\n",
    "  9.0,\n",
    "  20.0,\n",
    "  2022.0,\n",
    "  3.0,\n",
    "  94.93576927668948,\n",
    "  97.7187873924136,\n",
    "  106.5675777935643,\n",
    "  133.46975024736352,\n",
    "  77.82557137676875,\n",
    "  26.886240262965835,\n",
    "  93.80764940773277,\n",
    "  28.67887997302126,\n",
    "  113.67518074451117,\n",
    "  30.4468958883678],\n",
    " [2.0,\n",
    "  9.0,\n",
    "  21.0,\n",
    "  2022.0,\n",
    "  3.0,\n",
    "  92.32230830172934,\n",
    "  34.350356241745,\n",
    "  112.97609292100049,\n",
    "  99.21268633211206,\n",
    "  80.06729855054992,\n",
    "  23.0356600622431,\n",
    "  89.31238894610509,\n",
    "  30.32804828287802,\n",
    "  112.03617274871455,\n",
    "  32.50610622726534],\n",
    " [3.0,\n",
    "  9.0,\n",
    "  22.0,\n",
    "  2022.0,\n",
    "  3.0,\n",
    "  50.04244645821317,\n",
    "  77.85694616139921,\n",
    "  81.35399000575227,\n",
    "  125.84635801167887,\n",
    "  82.91003059614825,\n",
    "  23.927978474812306,\n",
    "  90.48396612287904,\n",
    "  30.31376940936954,\n",
    "  111.09982983101149,\n",
    "  32.49915610665346]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226d59e6b56c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.tools.mcp.mcp_client import MCPClient\n",
    "from utils.cognito_utils import get_token\n",
    "from utils.agent_utils import create_streamable_http_transport,get_full_tools_list \n",
    "import os\n",
    "\n",
    "def run_agent(mcp_url: str, access_token: str):\n",
    "    mcp_client = MCPClient(lambda: create_streamable_http_transport(mcp_url, access_token))\n",
    "     \n",
    "    with mcp_client:\n",
    "        tools = get_full_tools_list(mcp_client)\n",
    "        print(f\"Found the following tools: {[tool.tool_name for tool in tools]}\")\n",
    "\n",
    "        # Create an agent with these tools\n",
    "        agent = Agent(\n",
    "            model=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\", tools=tools\n",
    "        )\n",
    "        \n",
    "        # Invoke the agent\n",
    "        agent(\n",
    "            f\"These are the current demand values:\\n\\n<input>{test_sample}</input>\\n\\n\"\n",
    "            \"Predict demand, please. Provide the output in JSON format {'predictions':<predictions>}.\"\n",
    "            \"Only reply with the prediction JSON, nothing else. If the tool fails, just tell me the error.\"\n",
    "        )\n",
    "        \n",
    "# run_agent(<MCP URL>, <Access token>)\n",
    "run_agent(\"http://localhost:8000/mcp\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4_cognito_setup",
   "metadata": {},
   "source": [
    "## Setting up Amazon Cognito for Authentication\n",
    "\n",
    "AgentCore Runtime requires authentication. We'll use Amazon Cognito to provide JWT tokens for accessing our deployed MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_cognito",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_clients = gateway[\"authorizerConfiguration\"][\"customJWTAuthorizer\"][\"allowedClients\"]\n",
    "discovery_url = gateway[\"authorizerConfiguration\"][\"customJWTAuthorizer\"][\"discoveryUrl\"]\n",
    "role_arn = gateway[\"roleArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6_configure_deployment",
   "metadata": {},
   "source": [
    "## Configuring AgentCore Runtime Deployment\n",
    "\n",
    "Next we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/configure.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configure_runtime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "import time\n",
    "\n",
    "tool_name = \"endpoint_via_runtime\"\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "print(f\"Using AWS region: {region}\")\n",
    "\n",
    "required_files = ['mcp_server.py', 'requirements.txt']\n",
    "for file in required_files:\n",
    "    if not os.path.exists(file):\n",
    "        raise FileNotFoundError(f\"Required file {file} not found\")\n",
    "print(\"All required files found ✓\")\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "auth_config = {\n",
    "    \"customJWTAuthorizer\": {\n",
    "        \"allowedClients\": allowed_clients,\n",
    "        \"discoveryUrl\": discovery_url,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Configuring AgentCore Runtime...\")\n",
    "response = agentcore_runtime.configure(\n",
    "    agent_name=tool_name,\n",
    "    entrypoint=\"mcp_server.py\",\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    execution_role=role_arn,\n",
    "    authorizer_configuration=auth_config,\n",
    "    protocol=\"MCP\",\n",
    ")\n",
    "print(\"Configuration completed ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7_launch",
   "metadata": {},
   "source": [
    "## Launching MCP Server to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the MCP server to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"85%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Launching MCP server to AgentCore Runtime...\")\n",
    "print(\"This may take several minutes...\")\n",
    "launch_result = agentcore_runtime.launch()\n",
    "print(\"Launch completed ✓\")\n",
    "print(f\"Agent ARN: {launch_result.agent_arn}\")\n",
    "print(f\"Agent ID: {launch_result.agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8_check_status",
   "metadata": {},
   "source": [
    "## Checking AgentCore Runtime Status\n",
    "\n",
    "Now that we've deployed the AgentCore Runtime, let's check for its deployment status and wait for it to be ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking AgentCore Runtime status...\")\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "print(f\"Initial status: {status}\")\n",
    "\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    print(f\"Status: {status} - waiting...\")\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "\n",
    "if status == 'READY':\n",
    "    print(\"✓ AgentCore Runtime is READY!\")\n",
    "else:\n",
    "    print(f\"⚠ AgentCore Runtime status: {status}\")\n",
    "    \n",
    "print(f\"Final status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step9_store_credentials",
   "metadata": {},
   "source": [
    "## Storing Configuration for Remote Access\n",
    "\n",
    "Before we can invoke our deployed MCP server, let's store the Agent ARN and Cognito configuration in AWS Systems Manager Parameter Store and AWS Secrets Manager for easy retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "store_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_runtime_arn = launch_result.agent_arn\n",
    "encoded_arn = server_runtime_arn.replace(':', '%3A').replace('/', '%2F')\n",
    "mcp_url = f\"https://bedrock-agentcore.{region}.amazonaws.com/runtimes/{encoded_arn}/invocations?qualifier=DEFAULT\"\n",
    "mcp_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step10_remote_client",
   "metadata": {},
   "source": [
    "## Test the Agent with the remote MCP Server\n",
    "\n",
    "Now let's create a client to test our deployed MCP server. This client will retrieve the necessary credentials from AWS and connect to the deployed server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_remote_client",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.tools.mcp.mcp_client import MCPClient\n",
    "from utils.cognito_utils import get_token\n",
    "from utils.agent_utils import create_streamable_http_transport,get_full_tools_list \n",
    "import os\n",
    "\n",
    "def run_agent(mcp_url: str, access_token: str):\n",
    "    mcp_client = MCPClient(lambda: create_streamable_http_transport(mcp_url, access_token))\n",
    "     \n",
    "    with mcp_client:\n",
    "        tools = get_full_tools_list(mcp_client)\n",
    "        print(f\"Found the following tools: {[tool.tool_name for tool in tools]}\")\n",
    "\n",
    "        # Create an agent with these tools\n",
    "        agent = Agent(\n",
    "            model=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\", tools=tools\n",
    "        )\n",
    "        \n",
    "        # Invoke the agent\n",
    "        agent(\n",
    "            f\"These are the current demand values:\\n\\n<input>{test_sample}</input>\\n\\n\"\n",
    "            \"Predict demand, please. Provide the output in JSON format {'predictions':<predictions>}.\"\n",
    "            \"Only reply with the prediction JSON, nothing else. If the tool fails, just tell me the error.\"\n",
    "        )\n",
    "        \n",
    "# run_agent(<MCP URL>, <Access token>)\n",
    "run_agent(mcp_url, get_token(gateway[\"gatewayId\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congratulations",
   "metadata": {},
   "source": [
    "# 🎉 Congratulations!\n",
    "\n",
    "You have successfully:\n",
    "\n",
    "✅ **Created an MCP server** with custom tools  \n",
    "✅ **Tested locally** using MCP client  \n",
    "✅ **Set up authentication** with Amazon Cognito  \n",
    "✅ **Deployed to AWS** using AgentCore Runtime  \n",
    "✅ **Invoked remotely** with proper authentication  \n",
    "✅ **Learned MCP concepts** and best practices  \n",
    "\n",
    "Your MCP server is now running on Amazon Bedrock AgentCore Runtime and ready for production use!\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "- Build MCP servers using FastMCP\n",
    "- Configure stateless HTTP transport for AgentCore compatibility\n",
    "- Set up JWT authentication with Amazon Cognito\n",
    "- Deploy and manage MCP servers on AWS\n",
    "- Test both locally and remotely\n",
    "- Use MCP clients for tool invocation\n",
    "\n",
    "The deployed MCP server can now be integrated into larger AI applications and workflows!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
