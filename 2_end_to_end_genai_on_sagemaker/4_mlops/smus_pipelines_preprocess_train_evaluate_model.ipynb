{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f207c2b8",
   "metadata": {
    "papermill": {
     "duration": 0.029403,
     "end_time": "2022-07-13T16:07:44.040408",
     "exception": false,
     "start_time": "2022-07-13T16:07:44.011005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Orchestrate Jobs to Train and Evaluate Models with Amazon SageMaker Pipelines\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40bee569",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04756e",
   "metadata": {
    "papermill": {
     "duration": 0.029403,
     "end_time": "2022-07-13T16:07:44.040408",
     "exception": false,
     "start_time": "2022-07-13T16:07:44.011005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Amazon SageMaker Pipelines offers machine learning (ML) application developers and operations engineers the ability to orchestrate SageMaker jobs and author reproducible ML pipelines. It also enables them to deploy custom-built models for inference in real-time with low latency, run offline inferences with Batch Transform, and track lineage of artifacts. They can institute sound operational practices in deploying and monitoring production workflows, deploying model artifacts, and tracking artifact lineage through a simple interface, adhering to safety and best practice paradigms for ML application development.\n",
    "\n",
    "The SageMaker Pipelines service supports a SageMaker Pipeline domain specific language (DSL), which is a declarative JSON specification. This DSL defines a directed acyclic graph (DAG) of pipeline parameters and SageMaker job steps. The SageMaker Python Software Developer Kit (SDK) streamlines the generation of the pipeline DSL using constructs that engineers and scientists are already familiar with.\n",
    "\n",
    "## Runtime\n",
    "\n",
    "This notebook takes approximately an hour to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [SageMaker Pipelines](#SageMaker-Pipelines)\n",
    "1. [Notebook Overview](#Notebook-Overview)\n",
    "1. [A SageMaker Pipeline](#A-SageMaker-Pipeline)\n",
    "1. [Dataset](#Dataset)\n",
    "1. [Define Parameters to Parametrize Pipeline Execution](#Define-Parameters-to-Parametrize-Pipeline-Execution)\n",
    "1. [Define a Processing Step for Feature Engineering](#Define-a-Processing-Step-for-Feature-Engineering)\n",
    "1. [Define a Training Step to Train a Model](#Define-a-Training-Step-to-Train-a-Model)\n",
    "1. [Define a Model Evaluation Step to Evaluate the Trained Model](#Define-a-Model-Evaluation-Step-to-Evaluate-the-Trained-Model)\n",
    "1. [Define a Create Model Step to Create a Model](#Define-a-Create-Model-Step-to-Create-a-Model)\n",
    "1. [Define a Transform Step to Perform Batch Transformation](#Define-a-Transform-Step-to-Perform-Batch-Transformation)\n",
    "1. [Define a Register Model Step to Create a Model Package](#Define-a-Register-Model-Step-to-Create-a-Model-Package)\n",
    "1. [Define a Fail Step to Terminate the Pipeline Execution and Mark it as Failed](#Define-a-Fail-Step-to-Terminate-the-Pipeline-Execution-and-Mark-it-as-Failed)\n",
    "1. [Define a Condition Step to Check Accuracy and Conditionally Create a Model and Run a Batch Transformation and Register a Model in the Model Registry, Or Terminate the Execution in Failed State](#Define-a-Condition-Step-to-Check-Accuracy-and-Conditionally-Create-a-Model-and-Run-a-Batch-Transformation-and-Register-a-Model-in-the-Model-Registry,-Or-Terminate-the-Execution-in-Failed-State)\n",
    "1. [Define a Pipeline of Parameters, Steps, and Conditions](#Define-a-Pipeline-of-Parameters,-Steps,-and-Conditions)\n",
    "1. [Submit the pipeline to SageMaker and start execution](#Submit-the-pipeline-to-SageMaker-and-start-execution)\n",
    "1. [Pipeline Operations: Examining and Waiting for Pipeline Execution](#Pipeline-Operations:-Examining-and-Waiting-for-Pipeline-Execution)\n",
    "    1. [Examining the Evaluation](#Examining-the-Evaluation)\n",
    "    1. [Lineage](#Lineage)\n",
    "    1. [Parametrized Executions](#Parametrized-Executions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abefb0",
   "metadata": {
    "papermill": {
     "duration": 0.029368,
     "end_time": "2022-07-13T16:07:44.099261",
     "exception": false,
     "start_time": "2022-07-13T16:07:44.069893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SageMaker Pipelines\n",
    "\n",
    "SageMaker Pipelines supports the following activities, which are demonstrated in this notebook:\n",
    "\n",
    "* Pipelines - A DAG of steps and conditions to orchestrate SageMaker jobs and resource creation.\n",
    "* Processing job steps - A simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation.\n",
    "* Training job steps - An iterative process that teaches a model to make predictions by presenting examples from a training dataset.\n",
    "* Conditional execution steps - A step that provides conditional execution of branches in a pipeline.\n",
    "* Register model steps - A step that creates a model package resource in the Model Registry that can be used to create deployable models in Amazon SageMaker.\n",
    "* Create model steps - A step that creates a model for use in transform steps or later publication as an endpoint.\n",
    "* Transform job steps - A batch transform to preprocess datasets to remove noise or bias that interferes with training or inference from a dataset, get inferences from large datasets, and run inference when a persistent endpoint is not needed.\n",
    "* Fail steps - A step that stops a pipeline execution and marks the pipeline execution as failed.\n",
    "* Parametrized Pipeline executions - Enables variation in pipeline executions according to specified parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd6f33",
   "metadata": {
    "papermill": {
     "duration": 0.029618,
     "end_time": "2022-07-13T16:07:44.158330",
     "exception": false,
     "start_time": "2022-07-13T16:07:44.128712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "* Define a set of Pipeline parameters that can be used to parametrize a SageMaker Pipeline.\n",
    "* Define a Processing step that performs cleaning, feature engineering, and splitting the input data into train and test data sets.\n",
    "* Define a Training step that trains a model on the preprocessed train data set.\n",
    "* Define a Processing step that evaluates the trained model's performance on the test dataset.\n",
    "* Define a Create Model step that creates a model from the model artifacts used in training.\n",
    "* Define a Transform step that performs batch transformation based on the model that was created.\n",
    "* Define a Register Model step that creates a model package from the estimator and model artifacts used to train the model.\n",
    "* Define a Conditional step that measures a condition based on output from prior steps and conditionally executes other steps.\n",
    "* Define a Fail step with a customized error message indicating the cause of the execution failure.\n",
    "* Define and create a Pipeline definition in a DAG, with the defined parameters and steps.\n",
    "* Start a Pipeline execution and wait for execution to complete.\n",
    "* Download the model evaluation report from the S3 bucket for examination.\n",
    "* Start a second Pipeline execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38772d5a",
   "metadata": {
    "papermill": {
     "duration": 0.029536,
     "end_time": "2022-07-13T16:07:44.217483",
     "exception": false,
     "start_time": "2022-07-13T16:07:44.187947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## A SageMaker Pipeline\n",
    "\n",
    "The pipeline that you create follows a typical machine learning (ML) application pattern of preprocessing, training, evaluation, model creation, batch transformation, and model registration:\n",
    "\n",
    "![A typical ML Application pipeline](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-full.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607841c",
   "metadata": {
    "papermill": {
     "duration": 0.029684,
     "end_time": "2022-07-13T16:07:44.276589",
     "exception": false,
     "start_time": "2022-07-13T16:07:44.246905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset you use is the [UCI Machine Learning Abalone Dataset](https://archive.ics.uci.edu/ml/datasets/abalone) [1].  The aim for this task is to determine the age of an abalone snail from its physical measurements. At the core, this is a regression problem.\n",
    "\n",
    "The dataset contains several features: length (the longest shell measurement), diameter (the diameter perpendicular to length), height (the height with meat in the shell), whole_weight (the weight of whole abalone), shucked_weight (the weight of meat), viscera_weight (the gut weight after bleeding), shell_weight (the weight after being dried), sex ('M', 'F', 'I' where 'I' is Infant), and rings (integer).\n",
    "\n",
    "The number of rings turns out to be a good approximation for age (age is rings + 1.5). However, to obtain this number requires cutting the shell through the cone, staining the section, and counting the number of rings through a microscope, which is a time-consuming task. However, the other physical measurements are easier to determine. You use the dataset to build a predictive model of the variable rings through these other physical measurements.\n",
    "\n",
    "Before you upload the data to an S3 bucket, install the SageMaker Python SDK and gather some constants you can use later in this notebook.\n",
    "\n",
    "> [1] Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef441354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:10.529324Z",
     "iopub.status.busy": "2025-06-19T18:37:10.528964Z",
     "iopub.status.idle": "2025-06-19T18:37:15.669189Z",
     "shell.execute_reply": "2025-06-19T18:37:15.668381Z",
     "shell.execute_reply.started": "2025-06-19T18:37:10.529302Z"
    },
    "papermill": {
     "duration": 3.905415,
     "end_time": "2022-07-13T16:07:48.212278",
     "exception": false,
     "start_time": "2022-07-13T16:07:44.306863",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install \"sagemaker>=2.99.0\"\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "model_package_group_name = f\"AbaloneModelPackageGroupName\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0efd60e-618c-4a94-a001-781ebf4775f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:15.671336Z",
     "iopub.status.busy": "2025-06-19T18:37:15.671075Z",
     "iopub.status.idle": "2025-06-19T18:37:15.675362Z",
     "shell.execute_reply": "2025-06-19T18:37:15.674514Z",
     "shell.execute_reply.started": "2025-06-19T18:37:15.671312Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Using Execution Role: {role}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f70f4",
   "metadata": {
    "papermill": {
     "duration": 0.031185,
     "end_time": "2022-07-13T16:07:48.274459",
     "exception": false,
     "start_time": "2022-07-13T16:07:48.243274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, upload the data into the default bucket. You can select our own data set for the `input_data_uri` as is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c8059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:15.679587Z",
     "iopub.status.busy": "2025-06-19T18:37:15.679274Z",
     "iopub.status.idle": "2025-06-19T18:37:15.845969Z",
     "shell.execute_reply": "2025-06-19T18:37:15.844639Z",
     "shell.execute_reply.started": "2025-06-19T18:37:15.679558Z"
    },
    "papermill": {
     "duration": 0.19199,
     "end_time": "2022-07-13T16:07:48.498111",
     "exception": false,
     "start_time": "2022-07-13T16:07:48.306121",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a83533-6801-4eb9-a99b-c72c9650b000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:15.848156Z",
     "iopub.status.busy": "2025-06-19T18:37:15.847763Z",
     "iopub.status.idle": "2025-06-19T18:37:19.037778Z",
     "shell.execute_reply": "2025-06-19T18:37:19.036912Z",
     "shell.execute_reply.started": "2025-06-19T18:37:15.848128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lookup Sagemaker Unified Studio project attributes using Project() class:\n",
    "from sagemaker_studio import Project\n",
    "project = Project()\n",
    "\n",
    "print(project.id)\n",
    "print(project.name)\n",
    "print(project.domain_id)\n",
    "print(project.project_status)\n",
    "print(project.domain_unit_id)\n",
    "print(project.project_profile_id)\n",
    "print(project.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c9b42-3e3e-4505-bb90-36ccd9d4f3b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:19.039046Z",
     "iopub.status.busy": "2025-06-19T18:37:19.038770Z",
     "iopub.status.idle": "2025-06-19T18:37:19.189962Z",
     "shell.execute_reply": "2025-06-19T18:37:19.189107Z",
     "shell.execute_reply.started": "2025-06-19T18:37:19.038986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lookup Sagemaker Unified Studio Project S3 locations:\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "print(f'SMUS default bucket: {default_bucket}')\n",
    "print(f'SMUS default prefix: {default_prefix}')\n",
    "\n",
    "smus_base_path = f\"s3://{default_bucket}/{default_prefix}/\"\n",
    "print(smus_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0eeeb-00c0-4adb-8598-b05d8c63bbeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:19.191379Z",
     "iopub.status.busy": "2025-06-19T18:37:19.191078Z",
     "iopub.status.idle": "2025-06-19T18:37:19.879468Z",
     "shell.execute_reply": "2025-06-19T18:37:19.876206Z",
     "shell.execute_reply.started": "2025-06-19T18:37:19.191346Z"
    },
    "papermill": {
     "duration": 1.041888,
     "end_time": "2022-07-13T16:07:49.571370",
     "exception": false,
     "start_time": "2022-07-13T16:07:48.529482",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download data file from Public S3 bucket\n",
    "\n",
    "local_path = \"data/abalone-dataset.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-sample-files\").download_file(\n",
    "    \"datasets/tabular/uci_abalone/abalone.csv\", local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9634ec-899d-4e74-91a9-46d367d572ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:19.884710Z",
     "iopub.status.busy": "2025-06-19T18:37:19.881226Z",
     "iopub.status.idle": "2025-06-19T18:37:20.391774Z",
     "shell.execute_reply": "2025-06-19T18:37:20.390457Z",
     "shell.execute_reply.started": "2025-06-19T18:37:19.884655Z"
    },
    "papermill": {
     "duration": 1.041888,
     "end_time": "2022-07-13T16:07:49.571370",
     "exception": false,
     "start_time": "2022-07-13T16:07:48.529482",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Sagemaker Unified Studio default prefix to path\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/{default_prefix}/abalone\"\n",
    "\n",
    "# Upload file to S3\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(input_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6ec51",
   "metadata": {
    "papermill": {
     "duration": 0.033529,
     "end_time": "2022-07-13T16:07:49.637761",
     "exception": false,
     "start_time": "2022-07-13T16:07:49.604232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Download a second dataset for batch transformation after model creation. You can select our own dataset for the `batch_data_uri` as is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394aaee-6c3e-4781-8346-36cce2746f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:20.395755Z",
     "iopub.status.busy": "2025-06-19T18:37:20.395452Z",
     "iopub.status.idle": "2025-06-19T18:37:20.531475Z",
     "shell.execute_reply": "2025-06-19T18:37:20.530713Z",
     "shell.execute_reply.started": "2025-06-19T18:37:20.395722Z"
    },
    "papermill": {
     "duration": 0.530874,
     "end_time": "2022-07-13T16:07:50.208271",
     "exception": false,
     "start_time": "2022-07-13T16:07:49.677397",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_path = \"data/abalone-dataset-batch\"\n",
    "\n",
    "s3.Bucket(f\"sagemaker-servicecatalog-seedcode-{region}\").download_file(\n",
    "    \"dataset/abalone-dataset-batch\", local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48814c03-0a3d-443d-9e1e-d952777e993a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:20.532453Z",
     "iopub.status.busy": "2025-06-19T18:37:20.532190Z",
     "iopub.status.idle": "2025-06-19T18:37:21.028300Z",
     "shell.execute_reply": "2025-06-19T18:37:21.027357Z",
     "shell.execute_reply.started": "2025-06-19T18:37:20.532435Z"
    },
    "papermill": {
     "duration": 0.530874,
     "end_time": "2022-07-13T16:07:50.208271",
     "exception": false,
     "start_time": "2022-07-13T16:07:49.677397",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Sagemaker Unified Studio default prefix to path\n",
    "\n",
    "# Upload file to S3\n",
    "batch_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(batch_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b427e",
   "metadata": {
    "papermill": {
     "duration": 0.054012,
     "end_time": "2022-07-13T16:07:50.311578",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.257566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Parameters to Parametrize Pipeline Execution\n",
    "\n",
    "Define Pipeline parameters that you can use to parametrize the pipeline. Parameters enable custom pipeline executions and schedules without having to modify the Pipeline definition.\n",
    "\n",
    "The supported parameter types include:\n",
    "\n",
    "* `ParameterString` - represents a `str` Python type\n",
    "* `ParameterInteger` - represents an `int` Python type\n",
    "* `ParameterFloat` - represents a `float` Python type\n",
    "\n",
    "These parameters support providing a default value, which can be overridden on pipeline execution. The default value specified should be an instance of the type of the parameter.\n",
    "\n",
    "The parameters defined in this workflow include:\n",
    "\n",
    "* `processing_instance_count` - The instance count of the processing job.\n",
    "* `instance_type` - The `ml.*` instance type of the training job.\n",
    "* `model_approval_status` - The approval status to register with the trained model for CI/CD purposes (\"PendingManualApproval\" is the default).\n",
    "* `input_data` - The S3 bucket URI location of the input data.\n",
    "* `batch_data` - The S3 bucket URI location of the batch data.\n",
    "* `mse_threshold` - The Mean Squared Error (MSE) threshold used to verify the accuracy of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730dc01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:21.034137Z",
     "iopub.status.busy": "2025-06-19T18:37:21.033273Z",
     "iopub.status.idle": "2025-06-19T18:37:21.040164Z",
     "shell.execute_reply": "2025-06-19T18:37:21.039422Z",
     "shell.execute_reply.started": "2025-06-19T18:37:21.034102Z"
    },
    "papermill": {
     "duration": 0.058807,
     "end_time": "2022-07-13T16:07:50.424032",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.365225",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_data_uri,\n",
    ")\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2113cab9",
   "metadata": {
    "papermill": {
     "duration": 0.061565,
     "end_time": "2022-07-13T16:07:50.532413",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.470848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define Parameters](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0279c19d",
   "metadata": {
    "papermill": {
     "duration": 0.034918,
     "end_time": "2022-07-13T16:07:50.601674",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.566756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a Processing Step for Feature Engineering\n",
    "\n",
    "First, develop a preprocessing script that is specified in the Processing step.\n",
    "\n",
    "This notebook cell writes a file `preprocessing_abalone.py`, which contains the preprocessing script. You can update the script, and rerun this cell to overwrite. The preprocessing script uses `scikit-learn` to do the following:\n",
    "\n",
    "* Fill in missing sex category data and encode it so that it is suitable for training.\n",
    "* Scale and normalize all numerical fields, aside from sex and rings numerical data.\n",
    "* Split the data into training, validation, and test datasets.\n",
    "\n",
    "The Processing step executes the script on the input data. The Training step uses the preprocessed training features and labels to train a model. The Evaluation step uses the trained model and preprocessed test features and labels to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b07a322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:21.046219Z",
     "iopub.status.busy": "2025-06-19T18:37:21.045931Z",
     "iopub.status.idle": "2025-06-19T18:37:21.215360Z",
     "shell.execute_reply": "2025-06-19T18:37:21.214359Z",
     "shell.execute_reply.started": "2025-06-19T18:37:21.046191Z"
    },
    "papermill": {
     "duration": 0.19357,
     "end_time": "2022-07-13T16:07:50.827884",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.634314",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901891e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:21.217649Z",
     "iopub.status.busy": "2025-06-19T18:37:21.217172Z",
     "iopub.status.idle": "2025-06-19T18:37:21.224586Z",
     "shell.execute_reply": "2025-06-19T18:37:21.223857Z",
     "shell.execute_reply.started": "2025-06-19T18:37:21.217619Z"
    },
    "papermill": {
     "duration": 0.043198,
     "end_time": "2022-07-13T16:07:50.903065",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.859867",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753400dc",
   "metadata": {
    "papermill": {
     "duration": 0.03212,
     "end_time": "2022-07-13T16:07:50.967490",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.935370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, create an instance of a `SKLearnProcessor` processor and use that in our `ProcessingStep`.\n",
    "\n",
    "You also specify the `framework_version` to use throughout this notebook.\n",
    "\n",
    "Note the `processing_instance_count` parameter used by the processor instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3563172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:21.229119Z",
     "iopub.status.busy": "2025-06-19T18:37:21.228287Z",
     "iopub.status.idle": "2025-06-19T18:37:22.096349Z",
     "shell.execute_reply": "2025-06-19T18:37:22.095613Z",
     "shell.execute_reply.started": "2025-06-19T18:37:21.229088Z"
    },
    "papermill": {
     "duration": 0.056125,
     "end_time": "2022-07-13T16:07:51.055993",
     "exception": false,
     "start_time": "2022-07-13T16:07:50.999868",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1d463",
   "metadata": {
    "papermill": {
     "duration": 0.032682,
     "end_time": "2022-07-13T16:07:51.121085",
     "exception": false,
     "start_time": "2022-07-13T16:07:51.088403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we take the output of the processor's `run` method and pass that as arguments to the `ProcessingStep`. By passing the `pipeline_session` to the `sagemaker_session`, calling `.run()` does not launch the processing job, it returns the arguments needed to run the job as a step in the pipeline.\n",
    "\n",
    "Note the `\"train_data\"` and `\"test_data\"` named channels specified in the output configuration for the processing job. Step `Properties` can be used in subsequent steps and resolve to their runtime values at execution. Specifically, this usage is called out when you define the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240281be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:22.099654Z",
     "iopub.status.busy": "2025-06-19T18:37:22.099384Z",
     "iopub.status.idle": "2025-06-19T18:37:22.111367Z",
     "shell.execute_reply": "2025-06-19T18:37:22.110609Z",
     "shell.execute_reply.started": "2025-06-19T18:37:22.099635Z"
    },
    "papermill": {
     "duration": 0.39512,
     "end_time": "2022-07-13T16:07:51.548594",
     "exception": false,
     "start_time": "2022-07-13T16:07:51.153474",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"AbaloneProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f9bb1",
   "metadata": {
    "papermill": {
     "duration": 0.033806,
     "end_time": "2022-07-13T16:07:51.617961",
     "exception": false,
     "start_time": "2022-07-13T16:07:51.584155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define a Processing Step for Feature Engineering](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc187225",
   "metadata": {
    "papermill": {
     "duration": 0.040739,
     "end_time": "2022-07-13T16:07:51.691562",
     "exception": false,
     "start_time": "2022-07-13T16:07:51.650823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a Training Step to Train a Model\n",
    "\n",
    "In this section, use Amazon SageMaker's [XGBoost Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) to train on this dataset. Configure an Estimator for the XGBoost algorithm and the input dataset. A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later.\n",
    "\n",
    "The model path where the models from training are saved is also specified.\n",
    "\n",
    "Note the `instance_type` parameter may be used in multiple places in the pipeline. In this case, the `instance_type` is passed into the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407bef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:22.117177Z",
     "iopub.status.busy": "2025-06-19T18:37:22.116835Z",
     "iopub.status.idle": "2025-06-19T18:37:23.397205Z",
     "shell.execute_reply": "2025-06-19T18:37:23.396127Z",
     "shell.execute_reply.started": "2025-06-19T18:37:22.117148Z"
    },
    "papermill": {
     "duration": 0.171801,
     "end_time": "2022-07-13T16:07:51.897137",
     "exception": false,
     "start_time": "2022-07-13T16:07:51.725336",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/{default_prefix}/AbaloneTrain\"\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:linear\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "\n",
    "train_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86374ad",
   "metadata": {
    "papermill": {
     "duration": 0.064705,
     "end_time": "2022-07-13T16:07:51.995767",
     "exception": false,
     "start_time": "2022-07-13T16:07:51.931062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we use the output of the estimator's `.fit()` method as arguments to the `TrainingStep`. By passing the `pipeline_session` to the `sagemaker_session`, calling `.fit()` does not launch the training job, it returns the arguments needed to run the job as a step in the pipeline.\n",
    "\n",
    "Pass in the `S3Uri` of the `\"train_data\"` output channel to the `.fit()` method. Also, use the other `\"test_data\"` output channel for model evaluation in the pipeline. The `properties` attribute of a Pipeline step matches the object model of the corresponding response of a describe call. These properties can be referenced as placeholder values and are resolved at runtime. For example, the `ProcessingStep` `properties` attribute matches the object model of the [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d8eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:23.400506Z",
     "iopub.status.busy": "2025-06-19T18:37:23.400299Z",
     "iopub.status.idle": "2025-06-19T18:37:23.404688Z",
     "shell.execute_reply": "2025-06-19T18:37:23.403911Z",
     "shell.execute_reply.started": "2025-06-19T18:37:23.400488Z"
    },
    "papermill": {
     "duration": 0.103611,
     "end_time": "2022-07-13T16:07:52.196480",
     "exception": false,
     "start_time": "2022-07-13T16:07:52.092869",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7285f",
   "metadata": {
    "papermill": {
     "duration": 0.097979,
     "end_time": "2022-07-13T16:07:52.392020",
     "exception": false,
     "start_time": "2022-07-13T16:07:52.294041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define a Training Step to Train a Model](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58bfa7",
   "metadata": {
    "papermill": {
     "duration": 0.097153,
     "end_time": "2022-07-13T16:07:52.586494",
     "exception": false,
     "start_time": "2022-07-13T16:07:52.489341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a Model Evaluation Step to Evaluate the Trained Model\n",
    "\n",
    "First, develop an evaluation script that is specified in a Processing step that performs the model evaluation.\n",
    "\n",
    "After pipeline execution, you can examine the resulting `evaluation.json` for analysis.\n",
    "\n",
    "The evaluation script uses `xgboost` to do the following:\n",
    "\n",
    "* Load the model.\n",
    "* Read the test data.\n",
    "* Issue predictions against the test data.\n",
    "* Build a classification report, including accuracy and ROC curve.\n",
    "* Save the evaluation report to the evaluation directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a42f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:23.409771Z",
     "iopub.status.busy": "2025-06-19T18:37:23.409496Z",
     "iopub.status.idle": "2025-06-19T18:37:23.414730Z",
     "shell.execute_reply": "2025-06-19T18:37:23.413977Z",
     "shell.execute_reply.started": "2025-06-19T18:37:23.409751Z"
    },
    "papermill": {
     "duration": 0.184948,
     "end_time": "2022-07-13T16:07:52.869516",
     "exception": false,
     "start_time": "2022-07-13T16:07:52.684568",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile code/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": mse, \"standard_deviation\": std},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db80eee",
   "metadata": {
    "papermill": {
     "duration": 0.033789,
     "end_time": "2022-07-13T16:07:52.999885",
     "exception": false,
     "start_time": "2022-07-13T16:07:52.966096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, create an instance of a `ScriptProcessor` processor and use it in the `ProcessingStep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53230930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:23.421541Z",
     "iopub.status.busy": "2025-06-19T18:37:23.421188Z",
     "iopub.status.idle": "2025-06-19T18:37:24.302164Z",
     "shell.execute_reply": "2025-06-19T18:37:24.300574Z",
     "shell.execute_reply.started": "2025-06-19T18:37:23.421516Z"
    },
    "papermill": {
     "duration": 0.242851,
     "end_time": "2022-07-13T16:07:53.339481",
     "exception": false,
     "start_time": "2022-07-13T16:07:53.096630",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluation.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858206cd",
   "metadata": {
    "papermill": {
     "duration": 0.097754,
     "end_time": "2022-07-13T16:07:53.494882",
     "exception": false,
     "start_time": "2022-07-13T16:07:53.397128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use the processor's arguments returned by `.run()` to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution.\n",
    "\n",
    "Specifically, the `S3ModelArtifacts` from the `step_train` `properties` and the `S3Uri` of the `\"test_data\"` output channel of the `step_process` `properties` are passed as inputs. The `TrainingStep` and `ProcessingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) and [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response objects, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae643d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:24.305101Z",
     "iopub.status.busy": "2025-06-19T18:37:24.304849Z",
     "iopub.status.idle": "2025-06-19T18:37:24.309194Z",
     "shell.execute_reply": "2025-06-19T18:37:24.308195Z",
     "shell.execute_reply.started": "2025-06-19T18:37:24.305081Z"
    },
    "papermill": {
     "duration": 0.104102,
     "end_time": "2022-07-13T16:07:53.696669",
     "exception": false,
     "start_time": "2022-07-13T16:07:53.592567",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1a3c2",
   "metadata": {
    "papermill": {
     "duration": 0.096611,
     "end_time": "2022-07-13T16:07:53.966367",
     "exception": false,
     "start_time": "2022-07-13T16:07:53.869756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define a Model Evaluation Step to Evaluate the Trained Model](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0a560",
   "metadata": {
    "papermill": {
     "duration": 0.097005,
     "end_time": "2022-07-13T16:07:54.096931",
     "exception": false,
     "start_time": "2022-07-13T16:07:53.999926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a Create Model Step to Create a Model\n",
    "\n",
    "In order to perform batch transformation using the example model, create a SageMaker model.\n",
    "\n",
    "Specifically, pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties. The `TrainingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab382f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:24.317226Z",
     "iopub.status.busy": "2025-06-19T18:37:24.316961Z",
     "iopub.status.idle": "2025-06-19T18:37:24.752896Z",
     "shell.execute_reply": "2025-06-19T18:37:24.752142Z",
     "shell.execute_reply.started": "2025-06-19T18:37:24.317206Z"
    },
    "papermill": {
     "duration": 0.103791,
     "end_time": "2022-07-13T16:07:54.293572",
     "exception": false,
     "start_time": "2022-07-13T16:07:54.189781",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be254b",
   "metadata": {
    "papermill": {
     "duration": 0.099816,
     "end_time": "2022-07-13T16:07:54.490471",
     "exception": false,
     "start_time": "2022-07-13T16:07:54.390655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define the `ModelStep` by providing the return values from `model.create()` as the step arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8dc222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:24.756320Z",
     "iopub.status.busy": "2025-06-19T18:37:24.756030Z",
     "iopub.status.idle": "2025-06-19T18:37:25.707507Z",
     "shell.execute_reply": "2025-06-19T18:37:25.706785Z",
     "shell.execute_reply.started": "2025-06-19T18:37:24.756289Z"
    },
    "papermill": {
     "duration": 0.106688,
     "end_time": "2022-07-13T16:07:54.694631",
     "exception": false,
     "start_time": "2022-07-13T16:07:54.587943",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"AbaloneCreateModel\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.large\", accelerator_type=\"ml.eia1.medium\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49268979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:25.708967Z",
     "iopub.status.busy": "2025-06-19T18:37:25.708506Z",
     "iopub.status.idle": "2025-06-19T18:37:26.781548Z",
     "shell.execute_reply": "2025-06-19T18:37:26.780789Z",
     "shell.execute_reply.started": "2025-06-19T18:37:25.708938Z"
    },
    "papermill": {
     "duration": 0.106521,
     "end_time": "2022-07-13T16:07:55.991800",
     "exception": false,
     "start_time": "2022-07-13T16:07:55.885279",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1622708",
   "metadata": {
    "papermill": {
     "duration": 0.093149,
     "end_time": "2022-07-13T16:07:56.186199",
     "exception": false,
     "start_time": "2022-07-13T16:07:56.093050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define a Create Model Step and Batch Transform to Process Data in Batch at Scale](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756157c0",
   "metadata": {
    "papermill": {
     "duration": 0.097569,
     "end_time": "2022-07-13T16:07:56.381372",
     "exception": false,
     "start_time": "2022-07-13T16:07:56.283803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a Fail Step to Terminate the Pipeline Execution and Mark it as Failed\n",
    "\n",
    "This section walks you through the following steps:\n",
    "\n",
    "* Define a `FailStep` with customized error message, which indicates the cause of the execution failure.\n",
    "* Enter the `FailStep` error message with a `Join` function, which appends a static text string with the dynamic `mse_threshold` parameter to build a more informative error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041c8a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:26.786951Z",
     "iopub.status.busy": "2025-06-19T18:37:26.786318Z",
     "iopub.status.idle": "2025-06-19T18:37:26.792007Z",
     "shell.execute_reply": "2025-06-19T18:37:26.791104Z",
     "shell.execute_reply.started": "2025-06-19T18:37:26.786918Z"
    },
    "papermill": {
     "duration": 0.193196,
     "end_time": "2022-07-13T16:07:56.675378",
     "exception": false,
     "start_time": "2022-07-13T16:07:56.482182",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "step_fail = FailStep(\n",
    "    name=\"AbaloneMSEFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to MSE >\", mse_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf7e9c",
   "metadata": {
    "papermill": {
     "duration": 0.182821,
     "end_time": "2022-07-13T16:07:56.967379",
     "exception": false,
     "start_time": "2022-07-13T16:07:56.784558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define a Fail Step to Terminate the Execution in Failed State](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd777542",
   "metadata": {
    "papermill": {
     "duration": 0.034317,
     "end_time": "2022-07-13T16:07:57.099302",
     "exception": false,
     "start_time": "2022-07-13T16:07:57.064985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a Condition Step to Check Accuracy and Conditionally Create a Model, Or Terminate the Execution in Failed State\n",
    "\n",
    "In this step, the model is registered only if the accuracy of the model, as determined by the evaluation step `step_eval`, exceeded a specified value. Otherwise, the pipeline execution fails and terminates. A `ConditionStep` enables pipelines to support conditional execution in the pipeline DAG based on the conditions of the step properties.\n",
    "\n",
    "In the following section, you:\n",
    "\n",
    "* Define a `ConditionLessThanOrEqualTo` on the accuracy value found in the output of the evaluation step, `step_eval`.\n",
    "* Use the condition in the list of conditions in a `ConditionStep`.\n",
    "* Pass the `CreateModelStep` into the `if_steps` of the `ConditionStep`, which are only executed if the condition evaluates to `True`.\n",
    "* Pass the `FailStep` step into the `else_steps`of the `ConditionStep`, which is only executed if the condition evaluates to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969e1fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:26.797519Z",
     "iopub.status.busy": "2025-06-19T18:37:26.797250Z",
     "iopub.status.idle": "2025-06-19T18:37:26.806747Z",
     "shell.execute_reply": "2025-06-19T18:37:26.806113Z",
     "shell.execute_reply.started": "2025-06-19T18:37:26.797491Z"
    },
    "papermill": {
     "duration": 0.171087,
     "end_time": "2022-07-13T16:07:57.368032",
     "exception": false,
     "start_time": "2022-07-13T16:07:57.196945",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=mse_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"AbaloneMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772154ec",
   "metadata": {
    "papermill": {
     "duration": 0.098709,
     "end_time": "2022-07-13T16:07:57.564590",
     "exception": false,
     "start_time": "2022-07-13T16:07:57.465881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define a Condition Step to Check Accuracy and Conditionally Execute Steps](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd8a7d1",
   "metadata": {
    "papermill": {
     "duration": 0.097983,
     "end_time": "2022-07-13T16:07:57.697262",
     "exception": false,
     "start_time": "2022-07-13T16:07:57.599279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define a Pipeline of Parameters, Steps, and Conditions\n",
    "\n",
    "In this section, combine the steps into a Pipeline so it can be executed.\n",
    "\n",
    "A pipeline requires a `name`, `parameters`, and `steps`. Names must be unique within an `(account, region)` pair.\n",
    "\n",
    "Note:\n",
    "\n",
    "* All the parameters used in the definitions must be present.\n",
    "* Steps passed into the pipeline do not have to be listed in the order of execution. The SageMaker Pipeline service resolves the data dependency DAG as steps for the execution to complete.\n",
    "* Steps must be unique to across the pipeline step list and all condition step if/else lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7ea0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:26.813642Z",
     "iopub.status.busy": "2025-06-19T18:37:26.813084Z",
     "iopub.status.idle": "2025-06-19T18:37:27.191931Z",
     "shell.execute_reply": "2025-06-19T18:37:27.191206Z",
     "shell.execute_reply.started": "2025-06-19T18:37:26.813613Z"
    },
    "papermill": {
     "duration": 0.201248,
     "end_time": "2022-07-13T16:07:57.996214",
     "exception": false,
     "start_time": "2022-07-13T16:07:57.794966",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = f\"AbalonePipeline-v2-Test-NoAdd\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        batch_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7778c",
   "metadata": {
    "papermill": {
     "duration": 0.098305,
     "end_time": "2022-07-13T16:07:58.192290",
     "exception": false,
     "start_time": "2022-07-13T16:07:58.093985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![Define a Pipeline of Parameters, Steps, and Conditions](https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/sagemaker-pipelines/tabular/abalone_build_train_deploy/img/pipeline-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae8658",
   "metadata": {
    "papermill": {
     "duration": 0.097728,
     "end_time": "2022-07-13T16:07:58.394347",
     "exception": false,
     "start_time": "2022-07-13T16:07:58.296619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### (Optional) Examining the pipeline definition\n",
    "\n",
    "The JSON of the pipeline definition can be examined to confirm the pipeline is well-defined and the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a836b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:32.538704Z",
     "iopub.status.busy": "2025-06-19T18:37:32.538332Z",
     "iopub.status.idle": "2025-06-19T18:37:35.306361Z",
     "shell.execute_reply": "2025-06-19T18:37:35.305544Z",
     "shell.execute_reply.started": "2025-06-19T18:37:32.538678Z"
    },
    "papermill": {
     "duration": 0.18974,
     "end_time": "2022-07-13T16:07:58.684552",
     "exception": false,
     "start_time": "2022-07-13T16:07:58.494812",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b396c63",
   "metadata": {
    "papermill": {
     "duration": 0.093902,
     "end_time": "2022-07-13T16:07:58.880484",
     "exception": false,
     "start_time": "2022-07-13T16:07:58.786582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Submit the pipeline definition to the Pipeline service. The Pipeline service uses the role that is passed in to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944bcafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:43.577114Z",
     "iopub.status.busy": "2025-06-19T18:37:43.576101Z",
     "iopub.status.idle": "2025-06-19T18:37:47.033099Z",
     "shell.execute_reply": "2025-06-19T18:37:47.032219Z",
     "shell.execute_reply.started": "2025-06-19T18:37:43.577081Z"
    },
    "papermill": {
     "duration": 1.022416,
     "end_time": "2022-07-13T16:08:00.012097",
     "exception": false,
     "start_time": "2022-07-13T16:07:58.989681",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7133c2",
   "metadata": {
    "papermill": {
     "duration": 0.03559,
     "end_time": "2022-07-13T16:08:00.083359",
     "exception": false,
     "start_time": "2022-07-13T16:08:00.047769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Start the pipeline and accept all the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6f323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:50.579801Z",
     "iopub.status.busy": "2025-06-19T18:37:50.579232Z",
     "iopub.status.idle": "2025-06-19T18:37:50.777493Z",
     "shell.execute_reply": "2025-06-19T18:37:50.776677Z",
     "shell.execute_reply.started": "2025-06-19T18:37:50.579770Z"
    },
    "papermill": {
     "duration": 0.346706,
     "end_time": "2022-07-13T16:08:00.470006",
     "exception": false,
     "start_time": "2022-07-13T16:08:00.123300",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a608977",
   "metadata": {
    "papermill": {
     "duration": 0.040044,
     "end_time": "2022-07-13T16:08:00.552015",
     "exception": false,
     "start_time": "2022-07-13T16:08:00.511971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pipeline Operations: Examining and Waiting for Pipeline Execution\n",
    "\n",
    "Describe the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7140e583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:37:57.693788Z",
     "iopub.status.busy": "2025-06-19T18:37:57.693109Z",
     "iopub.status.idle": "2025-06-19T18:37:57.784313Z",
     "shell.execute_reply": "2025-06-19T18:37:57.783569Z",
     "shell.execute_reply.started": "2025-06-19T18:37:57.693759Z"
    },
    "papermill": {
     "duration": 0.388899,
     "end_time": "2022-07-13T16:08:00.980580",
     "exception": false,
     "start_time": "2022-07-13T16:08:00.591681",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d548cb82",
   "metadata": {
    "papermill": {
     "duration": 0.058959,
     "end_time": "2022-07-13T16:08:01.088218",
     "exception": false,
     "start_time": "2022-07-13T16:08:01.029259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wait for the execution to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97251833",
   "metadata": {
    "papermill": {
     "duration": 1149.995026,
     "end_time": "2022-07-13T16:27:11.118837",
     "exception": false,
     "start_time": "2022-07-13T16:08:01.123811",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc0b89",
   "metadata": {
    "papermill": {
     "duration": 0.038587,
     "end_time": "2022-07-13T16:27:11.202554",
     "exception": false,
     "start_time": "2022-07-13T16:27:11.163967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "List the steps in the execution. These are the steps in the pipeline that have been resolved by the step executor service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293013c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:45:47.278794Z",
     "iopub.status.busy": "2025-06-19T18:45:47.278078Z",
     "iopub.status.idle": "2025-06-19T18:45:47.421436Z",
     "shell.execute_reply": "2025-06-19T18:45:47.420426Z",
     "shell.execute_reply.started": "2025-06-19T18:45:47.278767Z"
    },
    "papermill": {
     "duration": 0.311444,
     "end_time": "2022-07-13T16:27:11.553327",
     "exception": false,
     "start_time": "2022-07-13T16:27:11.241883",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6e6aa",
   "metadata": {
    "papermill": {
     "duration": 0.043169,
     "end_time": "2022-07-13T16:27:11.634677",
     "exception": false,
     "start_time": "2022-07-13T16:27:11.591508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Examining the Evaluation\n",
    "\n",
    "Examine the resulting model evaluation after the pipeline completes. Download the resulting `evaluation.json` file from S3 and print the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151e408",
   "metadata": {
    "papermill": {
     "duration": 0.514239,
     "end_time": "2022-07-13T16:27:12.193344",
     "exception": false,
     "start_time": "2022-07-13T16:27:11.679105",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "evaluation_json = sagemaker.s3.S3Downloader.read_file(\n",
    "    \"{}/evaluation.json\".format(\n",
    "        step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "    )\n",
    ")\n",
    "pprint(json.loads(evaluation_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5a401",
   "metadata": {
    "papermill": {
     "duration": 0.045193,
     "end_time": "2022-07-13T16:27:49.331609",
     "exception": false,
     "start_time": "2022-07-13T16:27:49.286416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Parametrized Executions\n",
    "\n",
    "You can run additional executions of the pipeline and specify different pipeline parameters. The `parameters` argument is a dictionary containing parameter names, and where the values are used to override the defaults values.\n",
    "\n",
    "Based on the performance of the model, you might want to kick off another pipeline execution on a compute-optimized instance type and set the model approval status to \"Approved\" automatically. This means that the model package version generated by the `RegisterModel` step is automatically ready for deployment through CI/CD pipelines, such as with SageMaker Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b12dc2",
   "metadata": {
    "papermill": {
     "duration": 0.660009,
     "end_time": "2022-07-13T16:27:50.040517",
     "exception": false,
     "start_time": "2022-07-13T16:27:49.380508",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053eb92",
   "metadata": {
    "papermill": {
     "duration": 1089.265129,
     "end_time": "2022-07-13T16:45:59.346876",
     "exception": false,
     "start_time": "2022-07-13T16:27:50.081747",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498d8a3",
   "metadata": {
    "papermill": {
     "duration": 0.290742,
     "end_time": "2022-07-13T16:45:59.683052",
     "exception": false,
     "start_time": "2022-07-13T16:45:59.392310",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f9631d",
   "metadata": {
    "papermill": {
     "duration": 0.043074,
     "end_time": "2022-07-13T16:45:59.771340",
     "exception": false,
     "start_time": "2022-07-13T16:45:59.728266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Apart from that, you might also want to adjust the MSE threshold to a smaller value and raise the bar for the accuracy of the registered model. In this case you can override the MSE threshold like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f6820",
   "metadata": {
    "papermill": {
     "duration": 0.403974,
     "end_time": "2022-07-13T16:46:00.220070",
     "exception": false,
     "start_time": "2022-07-13T16:45:59.816096",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(parameters=dict(MseThreshold=3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f95d7",
   "metadata": {
    "papermill": {
     "duration": 0.078875,
     "end_time": "2022-07-13T16:46:00.342112",
     "exception": false,
     "start_time": "2022-07-13T16:46:00.263237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If the MSE threshold is not satisfied, the pipeline execution enters the `FailStep` and is marked as failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f244f42",
   "metadata": {
    "papermill": {
     "duration": 786.932424,
     "end_time": "2022-07-13T16:59:07.316785",
     "exception": false,
     "start_time": "2022-07-13T16:46:00.384361",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    execution.wait()\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62081cff",
   "metadata": {
    "papermill": {
     "duration": 0.238686,
     "end_time": "2022-07-13T16:59:07.610792",
     "exception": false,
     "start_time": "2022-07-13T16:59:07.372106",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15706063",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/ml_ops|sm-pipelines_preprocess_train_evaluate_batch_transform|sm-pipelines_preprocess_train_evaluate_batch_transform.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3085.109473,
   "end_time": "2022-07-13T16:59:08.278091",
   "environment_variables": {},
   "exception": null,
   "input_path": "sagemaker-pipelines-preprocess-train-evaluate-batch-transform.ipynb",
   "output_path": "/opt/ml/processing/output/sagemaker-pipelines-preprocess-train-evaluate-batch-transform-2022-07-13-15-54-21.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:000000000000:1234abcd-12ab-34cd-56ef-1234567890ab"
   },
   "start_time": "2022-07-13T16:07:43.168618",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
