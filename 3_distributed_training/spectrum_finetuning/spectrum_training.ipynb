{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad542e7-9ef8-41d1-9d6c-3c6c2efb7f19",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Spectrum Fine-Tuning with Amazon SageMaker AI \n",
    "\n",
    "In this example, you will learn how to use [Spectrum](https://github.com/QuixiAI/spectrum) along with Amazon SageMaker fully managed training jobs to fine-tune a Qwen3-8B model. \n",
    "\n",
    "Spectrum fine-tuning involves a few key steps:\n",
    "\n",
    "- First, Spectrum will download the desired model to be analyzed (automatically via AutoModelforCausalLM).\n",
    "- Then, it will run an analysis using to determine the Signal-to-Noise Ratio (SnR) for each layer in the model. Based on this analysis, Spectrum will create a subset of the data for specific layer percentages that can be used as input to the training job.\n",
    "- Next, you can use the training script provided in this example or implement the sample code into your own that can process the Spectrum output and selectively freeze or unfreeze layers accordingly.\n",
    "- Finally, you will create an Amazon SageMaker training job, providing the Spectrum analysis as an input.\n",
    "\n",
    "The goal of this process is to leverage Spectrum's insights about the model layers to fine-tune the model more effectively, by focusing the training on the most relevant layers. A complete sample can be found in the SageMaker Distributed Training GitHub repository. You'll see how Spectrum compares with QLoRA based fine-tuning and reduces resource requirements as well as training time, without a significant impact to model quality.\n",
    "\n",
    "![](./images/Spectrum-ValidationLoss-Comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca016c-d4fa-4213-a7b3-03b449551449",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Install the prerequisite packages to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907944ea-dbfb-4de0-9e13-1fd28c901031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r ./scripts/requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4299301-2b6c-4ec0-a2f8-33ddac2611b7",
   "metadata": {},
   "source": [
    "## This cell will restart the kernel. Click \"OK\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d9c10-965e-4fcd-86ff-3e788ec22b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c9e5c-c57c-42cd-baf4-e139422cc147",
   "metadata": {},
   "source": [
    "# Wait for the kernel to restart before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534deb95-7ba4-41de-9948-0ebc9b656b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import os\n",
    "from random import randint\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Model\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.config import load_sagemaker_config\n",
    "\n",
    "from sagemaker.modules.configs import Compute, InputData, OutputDataConfig, SourceCode, StoppingCondition\n",
    "from sagemaker.modules.distributed import Torchrun\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "from sagemaker.modules.configs import InputData\n",
    "\n",
    "from helper_functions import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61505d6f-948c-4b6f-adfc-2d9914e90254",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "configs = load_sagemaker_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd759d-797f-43a7-b9ef-f072986c309e",
   "metadata": {},
   "source": [
    "## Prepare spectrum Layer for training job\n",
    "\n",
    "Here you will clone the Spectrum repository into your local home directory so you can run analysis. \n",
    "\n",
    ">**Note:** If you have already cloned the repository and re-run the `git clone` command, it will return an error that the path already exists. You can ignore this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcdacbc-853f-4584-b2bd-3012ccf3359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_clone_folder = \"~/spectrum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1fec2-e6dc-4524-8149-e9b763c707b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/QuixiAI/spectrum.git {spectrum_clone_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbf3d8-afaa-442c-94d2-811f75e860f8",
   "metadata": {},
   "source": [
    "This example will use [Qwen3-8B](https://huggingface.co/Qwen/Qwen3-8B), if you'd like to use a different model, change the value for `model_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59050dab-6871-4309-8d40-ce4fd9de41d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen3-8B\"\n",
    "filesafe_model_id = model_id.replace(\"/\",\"-\")\n",
    "spectrum_layer_percent = \"10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934f829a-b7f8-4990-ab4a-8f1a65cde31d",
   "metadata": {},
   "source": [
    "## The following cell generates a shell command that you need to run in your terminal\n",
    "Spectrum's UI is interactive and cannot be run inside of this notebook. Please run the following cell, execute it in your terminal, then resume notebook execution. There is nothing from the terminal that you need to copy over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c518a62-5325-4697-b3c5-b2d55e96929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"cd {spectrum_clone_folder} && python3 {spectrum_clone_folder}/spectrum.py --model-name {model_id} --top-percent {spectrum_layer_percent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefe471-1275-42e7-9628-284e31aa42b4",
   "metadata": {},
   "source": [
    "## Ensure you executed the previous output in your terminal before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88efc8-e77d-4da2-8e00-4f00aae8496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_output_filename = f\"snr_results_{filesafe_model_id}_unfrozenparameters_{spectrum_layer_percent}percent.yaml\"\n",
    "spectrum_output_filepath = f\"{spectrum_clone_folder}/{spectrum_output_filename}\"\n",
    "spectrum_output_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ced138-7522-4c3b-b756-32d301307683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T21:24:22.413170Z",
     "iopub.status.busy": "2025-08-14T21:24:22.412772Z",
     "iopub.status.idle": "2025-08-14T21:24:22.418838Z",
     "shell.execute_reply": "2025-08-14T21:24:22.418071Z",
     "shell.execute_reply.started": "2025-08-14T21:24:22.413149Z"
    }
   },
   "source": [
    "This will copy the Spectrum output into your local scripts folder. It will be packaged with the code assets for your training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e30cb-639f-4e8a-8f77-6d232fefe904",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./scripts/spectrum-layer/\n",
    "!cp {spectrum_output_filepath} ./scripts/spectrum-layer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6105-ecec-4213-b56d-589238844dca",
   "metadata": {},
   "source": [
    "## Setup Configuration file path\n",
    "\n",
    "If you have created a Managed MLflow server, copy the `ARN` of the instance here and assign a name to the experiment. This will track your experiment in MLflow automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce51663-0171-4d54-b16e-f85e3cadb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"mlflow_uri\"] = \"\"\n",
    "os.environ[\"mlflow_experiment_name\"] = f\"spectrum-fine-tuning-{filesafe_model_id}-{spectrum_layer_percent}pct\"\n",
    "os.environ[\"hf_token\"] = \"\"\n",
    "os.environ[\"model_id\"] = model_id\n",
    "os.environ[\"spectrum_layer_config\"] = spectrum_output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b95b61-8666-4015-bf2e-fcf68ce38c5b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82089d28-b97a-4956-83fb-d8c46d44fdb5",
   "metadata": {},
   "source": [
    "## Visualize and upload the dataset\n",
    "\n",
    "We are going to read the data from huggingface and prepare it for the training job. This example uses the SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d13e1c-ef21-47c4-acfe-8773a6d20e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"rajpurkar/squad\", split=\"train\")\n",
    "test_dataset = load_dataset(\"rajpurkar/squad\", split=\"validation\")\n",
    "\n",
    "#grab a sample from the training and test sets\n",
    "print(f\"Train Sample:\\n{train_dataset[randint(0, len(train_dataset)-1)]}\\n\\n\")\n",
    "print(f\"Test Sample:\\n{test_dataset[randint(0, len(test_dataset)-1)]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e667af-8197-4d2f-8432-82db6a1d3006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T16:46:36.592759Z",
     "iopub.status.busy": "2024-12-17T16:46:36.591798Z",
     "iopub.status.idle": "2024-12-17T16:46:36.603128Z",
     "shell.execute_reply": "2024-12-17T16:46:36.598965Z",
     "shell.execute_reply.started": "2024-12-17T16:46:36.592728Z"
    }
   },
   "source": [
    "### Upload training data to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d0321-1bd5-4c62-845a-bb1b9a3891a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "if default_prefix:\n",
    "    input_path = f'{default_prefix}/datasets/spectrum-fine-tuning-modeltrainer-sft'\n",
    "else:\n",
    "    input_path = f'datasets/spectrum-fine-tuning-modeltrainer-sft'\n",
    "\n",
    "# Save datasets to s3\n",
    "# We will fine tune only with 20 records due to limited compute resource for the workshop\n",
    "train_dataset.to_json(\"./data/train/dataset.json\", orient=\"records\")\n",
    "test_dataset.to_json(\"./data/test/dataset.json\", orient=\"records\")\n",
    "\n",
    "s3_client.upload_file(\"./data/train/dataset.json\", bucket_name, f\"{input_path}/train/dataset.json\")\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.json\"\n",
    "s3_client.upload_file(\"./data/test/dataset.json\", bucket_name, f\"{input_path}/test/dataset.json\")\n",
    "test_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/test/dataset.json\"\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(test_dataset_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9c237-28bd-474e-9444-94aaea8e6979",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457beda-117d-4782-9f04-0680c199e98a",
   "metadata": {},
   "source": [
    "## Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5a09e-97de-4935-82c5-b56445e057fd",
   "metadata": {},
   "source": [
    "We are now ready to fine-tune our model. We will use the [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) from transfomers to fine-tune our model. We prepared a script [train_spectrum.py](./scripts/train_spectrum.py) which will loads the dataset from disk, prepare the model, tokenizer and start the training.\n",
    "\n",
    "For configuration we use `TrlParser`, that allows us to provide hyperparameters in a YAML file. This YAML will be uploaded and provided to Amazon SageMaker similar to our datasets. Below is the config file for fine-tuning the model on `ml.p4de.24xlarge`. We are saving the config file as `args.yaml` and upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5aaaf-7d2f-4aae-87af-1b9e6b11b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./args.yaml <<EOF\n",
    "\n",
    "hf_token: \"${hf_token}\" # Use HF token to login into Hugging Face to access the DeepSeek distilled models\n",
    "model_id: \"${model_id}\"       # Hugging Face model id\n",
    "mlflow_uri: \"${mlflow_uri}\"\n",
    "mlflow_experiment_name: \"${mlflow_experiment_name}\"\n",
    "\n",
    "# sagemaker specific parameters\n",
    "output_dir: \"/opt/ml/model\"                       # path to where SageMaker will upload the model \n",
    "train_dataset_path: \"/opt/ml/input/data/train/\"   # path to where FSx saves train dataset\n",
    "test_dataset_path: \"/opt/ml/input/data/test/\"     # path to where FSx saves test dataset\n",
    "\n",
    "\n",
    "enable_spectrum: true\n",
    "spectrum_config_path: \"/opt/ml/input/data/code/spectrum-layer/${spectrum_layer_config}\"\n",
    "\n",
    "#LoRA config\n",
    "enable_lora: false # enable LoRA training\n",
    "enable_quantization: false # set to true to also quantize the base model\n",
    "\n",
    "lora_r: 8\n",
    "lora_alpha: 16\n",
    "lora_dropout: 0.1\n",
    "merge_weights: true\n",
    "\n",
    "# training parameters           \n",
    "learning_rate: 2e-4                    # learning rate scheduler\n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "per_device_train_batch_size: 8         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "gradient_checkpointing: true           # use gradient checkpointing\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: false                            # use tf32 precision\n",
    "\n",
    "fsdp: \"full_shard auto_wrap offload\"\n",
    "fsdp_config: \n",
    "    backward_prefetch: \"backward_pre\"\n",
    "    cpu_ram_efficient_loading: true\n",
    "    offload_params: true\n",
    "    forward_prefetch: false\n",
    "    use_orig_params: true\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd27c7-d367-43b1-8b61-ce15e0e262c1",
   "metadata": {},
   "source": [
    "Upload the training configuration file to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70937e95-114e-40e1-b26a-49cc1cbd803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if default_prefix:\n",
    "    input_path = f\"s3://{bucket_name}/{default_prefix}/datasets/spectrum-fine-tuning-modeltrainer-sft\"\n",
    "else:\n",
    "    input_path = f\"s3://{bucket_name}/datasets/spectrum-fine-tuning-modeltrainer-sft\"\n",
    "\n",
    "# upload the model yaml file to s3\n",
    "model_yaml = \"args.yaml\"\n",
    "train_config_s3_path = S3Uploader.upload(local_path=model_yaml, desired_s3_uri=f\"{input_path}/config\")\n",
    "\n",
    "print(f\"Training config uploaded to:\")\n",
    "print(train_config_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329683c-6662-45d3-b864-9cb575f92599",
   "metadata": {},
   "source": [
    "## Fine-tune model\n",
    "\n",
    "In the following steps you will select an instance type, pull a managed training container, and configure a SageMaker AI fully managed training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cecfd-e640-4527-99d4-cb3cec9093b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.p4de.24xlarge\"\n",
    "\n",
    "instance_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178118a-0f45-4e5f-9bb1-7e5dee146b62",
   "metadata": {},
   "source": [
    "#### Get PyTorch image_uri\n",
    "\n",
    "We are going to use the native PyTorch container image, pre-built for Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df7700-7c66-4af8-aea0-da0e5af493bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"2.6.0\",\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\"\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac69607-e350-4543-97b6-507253f8ec6a",
   "metadata": {},
   "source": [
    "This training job setup uses the SageMaker Python SDK's `ModelTrainer` API to quickly configure the code and compute requirements for your training job.\n",
    "\n",
    "The `SourceCode` section references the code in this example, provides a `requirements.txt` file to handle training dependencies, and sets the desired S3 location for the trained model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cabb4d-b0b2-498c-95cb-41ed7d05ee65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:21.382486Z",
     "start_time": "2023-09-03T00:02:20.962208Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the script to be run\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"./scripts\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    entry_script=\"train_spectrum.py\",\n",
    ")\n",
    "\n",
    "# Define the compute\n",
    "compute_configs = Compute(\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    volume_size_in_gb=500,\n",
    "    #keep_alive_period_in_seconds=3600 #uncomment this value to enable warm pools\n",
    ")\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f\"train-{model_id.split('/')[-1].replace('.', '-')}-sft-spectrum-{spectrum_layer_percent}-script\"\n",
    "\n",
    "# define OutputDataConfig path\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "# Define the ModelTrainer\n",
    "model_trainer = ModelTrainer(\n",
    "    training_image=image_uri,\n",
    "    source_code=source_code,\n",
    "    base_job_name=job_name,\n",
    "    compute=compute_configs,\n",
    "    distributed=Torchrun(),\n",
    "    stopping_condition=StoppingCondition(\n",
    "        max_runtime_in_seconds=36000\n",
    "    ),\n",
    "    hyperparameters={\n",
    "        \"config\": \"/opt/ml/input/data/config/args.yaml\" # path to TRL config which was uploaded to s3\n",
    "    },\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=output_path\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe411845-847a-4f70-ab85-f428c6966a31",
   "metadata": {},
   "source": [
    "Here you will define different channels for training data, test data, and training configuration information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a386bd9-172c-485c-af45-ebc1d126470b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass the input data\n",
    "train_input = InputData(\n",
    "    channel_name=\"train\",\n",
    "    data_source=train_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "test_input = InputData(\n",
    "    channel_name=\"test\",\n",
    "    data_source=test_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "config_input = InputData(\n",
    "    channel_name=\"config\",\n",
    "    data_source=train_config_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "# Check input channels configured\n",
    "data = [train_input, test_input, config_input]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cedd237-28ae-4795-b522-1e6e551ba43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:12:36.197221Z",
     "iopub.status.busy": "2025-08-15T00:12:36.196807Z",
     "iopub.status.idle": "2025-08-15T00:12:36.202848Z",
     "shell.execute_reply": "2025-08-15T00:12:36.202114Z",
     "shell.execute_reply.started": "2025-08-15T00:12:36.197199Z"
    }
   },
   "source": [
    "With your `ModelTrainer` instance configured and data channels assigned, calling `train()` will start your training job.\n",
    "\n",
    "This will spin up the desired instance(s), download the training container, download the base model artifacts, and invoke the specified training script. When the job completes, the infrastructure will be terminated and the results will be stored in the S3 output location defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e13aa-1df2-43fc-bae4-15f5b7113191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "model_trainer.train(input_data_config=data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81686e-d27f-4c7b-bec6-f596e7dbaa32",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c71aeb-8999-4505-bc45-c2e7d90d723c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328b8fd-737d-4555-9824-56de5e202825",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "In the following sections, we are going to deploy the fine-tuned model on an Amazon SageMaker Real-time endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb892b35-ab33-4964-9947-f9487a1e50cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Fine-Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35481eff-1142-46f3-8e38-50a1bdadba7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T13:45:11.757861Z",
     "start_time": "2023-09-03T13:45:11.747993Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}-sft-spectrum-{spectrum_layer_percent}-script\"\n",
    "print(job_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4e9bd-de61-4806-b314-6bcf988a2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = utils.get_last_job_name(job_prefix)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eeba4b-cfc9-4aae-be86-8d2f3c4e5cb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29f2d8-b3b3-4b27-a0d2-e49812f56a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:10.492877Z",
     "start_time": "2023-11-20T18:41:10.488495Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g6e.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 900\n",
    "\n",
    "image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.33.0-lmi15.0.0-cu128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd6ef9-484a-4234-ba92-3c0ef95ccad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:12.433399Z",
     "start_time": "2023-11-20T18:41:11.963091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if default_prefix:\n",
    "    model_data=f\"s3://{bucket_name}/{default_prefix}/{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "else:\n",
    "    model_data=f\"s3://{bucket_name}/{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "        'OPTION_TRUST_REMOTE_CODE': 'true',\n",
    "        'OPTION_ROLLING_BATCH': \"vllm\",\n",
    "        'OPTION_DTYPE': 'bf16',\n",
    "        'OPTION_TENSOR_PARALLEL_DEGREE': 'max',\n",
    "        'OPTION_MAX_ROLLING_BATCH_SIZE': '32',\n",
    "        'OPTION_MODEL_LOADING_TIMEOUT': '3600',\n",
    "        'OPTION_MAX_MODEL_LEN': '4096'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30036f-9231-4de4-a03f-1297d2b6a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "endpoint_name = name_from_base(f\"{model_id.split('/')[-1].replace('.', '-')}-sft-djl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9035076-ac69-4859-9824-dcbf07c0f2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:45:49.265298Z",
     "start_time": "2023-11-20T18:41:14.621743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    model_data_download_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d0cac-4af1-4034-9f88-35861396c228",
   "metadata": {},
   "source": [
    "#### Predict\n",
    "\n",
    "This will create a `Predictor` using the SageMaker Python SDK to run inference against the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b040d-b8f4-4be0-9687-b28eff520236",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb48754-c24d-4f32-9f9d-7c8b1e8729fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"Answer the question based on the knowledge you have or shared by user. Just give the answer and do not explain your thinking process\"\n",
    "USER_PROMPT = \"What statue is in front of the Notre Dame building?\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "]\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"parameters\": {\"max_new_tokens\": 256, \"temperature\": 0.05}\n",
    "}\n",
    "\n",
    "output = predictor.predict(payload)\n",
    "\n",
    "print(f\"Output:\\n\\n{output['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff5d47-62d5-4751-828c-c6f998c33b16",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Delete Endpoint\n",
    "\n",
    "Set the `CLEAN_UP_ENDPOINT` flag to `True` and run the cleanup script to delete your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922957c-e7e3-46e3-86ea-8a8134c96bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set this value to True to delete resources.\n",
    "CLEAN_UP_ENDPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00feef6-e758-434d-8c36-b2212cccebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_UP_ENDPOINT:\n",
    "    endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-sft-djl\"\n",
    "    \n",
    "    predictor = sagemaker.Predictor(\n",
    "        endpoint_name=endpoint_name,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        serializer=sagemaker.serializers.JSONSerializer(),\n",
    "        deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    "    )\n",
    "    \n",
    "    predictor.delete_model()\n",
    "    predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
