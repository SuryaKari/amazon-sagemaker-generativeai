{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b466abd",
   "metadata": {},
   "source": [
    "# veRL on SageMaker\n",
    "\n",
    "### GRPO Algorithm Example\n",
    "\n",
    "Getting Started with veRL on SageMaker\n",
    "\n",
    "> **Note:** This example must be run from a machine with an NVIDIA GPU in order to build the docker image.\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "- create a .env file with the following variables:\n",
    "  - WANDB_API_KEY=XXXX\n",
    "  - HF_TOKEN=XXXX\n",
    "\n",
    "1. Build and push a veRL container to ECR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d294b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts = boto3.client('sts')\n",
    "sts.get_caller_identity()\n",
    "account = sts.get_caller_identity()['Account']\n",
    "boto_session = boto3.session.Session(region_name=region)\n",
    "region = boto_session.region_name\n",
    "boto_session\n",
    "\n",
    "# setup image name and tag\n",
    "image = \"verl-on-sagemaker\"\n",
    "tag = \"v1\"\n",
    "fullname = f\"{account}.dkr.ecr.{region}.amazonaws.com/{image}:{tag}\"\n",
    "\n",
    "fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebef4cc",
   "metadata": {},
   "source": [
    "> **NOTE** The below command should be run directly in bash and not from the notebook. It will fail if run from the notebook.\n",
    "\n",
    "```bash\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash container/build_tools/build_and_push.sh {region} {image} {tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57933ce2",
   "metadata": {},
   "source": [
    "2. Git clone the veRL repo, copy the example scripts to the local scripts directory, and execute the preprocessing script to download and format the gsm8k dataset. For simplicty we will upload our data straight from the scripts so it gets copied to our to our training instance and training container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# git clone https://github.com/volcengine/verl\n",
    "\n",
    "# mv verl/verl scripts/verl\n",
    "# mv verl/examples scripts/examples\n",
    "# rm -rf verl\n",
    "python3 scripts/examples/data_preprocess/gsm8k.py --local_dir scripts/data/gsm8k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e81ab8",
   "metadata": {},
   "source": [
    "3. Modify the example script so it knows where to find the data. The script we will run is located at `scripts/examples/grpo_trainer/run_qwen2-7b.sh`. Modify the following two lines in the script:\n",
    "\n",
    "```hightlight\n",
    "    data.train_files=data/gsm8k/train.parquet \\\n",
    "    data.val_files=data/gsm8k/test.parquet \\\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef73e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/$HOME/\\//' scripts/examples/data_preprocess/gsm8k.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a92d14",
   "metadata": {},
   "source": [
    "4. Execute a training job with the ModelTrainer API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import HfFolder\n",
    "from sagemaker.modules import Session\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "from sagemaker.modules.train.model_trainer import Mode\n",
    "from sagemaker.modules.configs import SourceCode, Compute, InputData\n",
    "\n",
    "sess = Session(boto3.session.Session(region_name=region))\n",
    "# iam = boto3.client('iam')\n",
    "# role = iam.get_role(RoleName='sagemaker')['Role']['Arn']\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# image URI for the training job\n",
    "# pytorch_image = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.6.0-gpu-py312-cu126-ubuntu22.04-sagemaker\"\n",
    "verl_image = fullname\n",
    "# you can find all available images here\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg-ecr-paths/sagemaker-algo-docker-registry-paths.html\n",
    "\n",
    "env = {\n",
    "    'WANDB_API_KEY': os.getenv('WANDB_API_KEY'),\n",
    "    'HF_TOKEN': HfFolder.get_token(),\n",
    "}\n",
    "\n",
    "# define the script to be run\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"scripts\", command='bash ./examples/grpo_trainer/run_qwen2-7b.sh'\n",
    ")\n",
    "\n",
    "# Compute configuration for the training job\n",
    "compute = Compute(\n",
    "    instance_count=1,\n",
    "    # for local mode\n",
    "    # instance_type='local_gpu',\n",
    "    instance_type=\"ml.p5.48xlarge\",\n",
    "    # instance_type=\"ml.p4d.24xlarge\",\n",
    "    volume_size_in_gb=96,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    ")\n",
    "\n",
    "# define the ModelTrainer\n",
    "model_trainer = ModelTrainer(\n",
    "    sagemaker_session=sess,\n",
    "    training_image=verl_image,\n",
    "    source_code=source_code,\n",
    "    base_job_name=\"verl-grpo-example\",\n",
    "    compute=compute,\n",
    "    environment=env,\n",
    "    # for local mode\n",
    "    # training_mode=Mode.LOCAL_CONTAINER,\n",
    ")\n",
    "\n",
    "# pass the input data\n",
    "# input_data = InputData(\n",
    "#     channel_name=\"train\",\n",
    "#     data_source=training_input_path,  #s3 path where training data is stored\n",
    "# )\n",
    "\n",
    "# start the training job\n",
    "model_trainer.train(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3e904",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c31bc",
   "metadata": {},
   "source": [
    "Testing a container manually before running in local mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db543cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker run --shm-size=10.24gb --gpus all -it 10489a46d273 bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542249a",
   "metadata": {},
   "source": [
    "SageMaker local docker compose command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker compose -f /home/ubuntu/verl-on-sagemaker/docker-compose.yaml up --build  --abort-on-container-exit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
