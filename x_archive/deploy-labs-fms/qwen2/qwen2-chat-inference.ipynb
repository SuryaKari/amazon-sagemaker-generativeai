{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f842db32-b1e7-439b-bd84-818fa1ee6eb0",
   "metadata": {},
   "source": [
    "# Create a sagemaker endpoint with Qwen2 0.5B model\n",
    "\n",
    "This notebook provides the steps to deploy Qwen2 (0.5B parameter size) into a sagemaker endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae1223-7f7e-4fb9-a94b-b994bab83a37",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f87074-51eb-41ff-8a06-3d176ed82abd",
   "metadata": {},
   "source": [
    "Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f39b53f-cfac-4f02-afc1-c97141681084",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker boto3 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c725f2c5-85ba-4d76-b3a6-14260a9d407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import jinja2\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5883f5c-9431-4d1d-a873-7cff28c43aa7",
   "metadata": {},
   "source": [
    "Retrieve role and session to use for the operations. Also, retrieve the S3 bucket that will store the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7404a065-e6b7-4822-baa2-d037e489a24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucketsagemaker-us-east-1-576219157147\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "model_bucket = sess.default_bucket()\n",
    "region = sess._region_name\n",
    "print(f\"Using bucket{model_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09050ad-17fa-4cf6-bb5c-b7239698f3a8",
   "metadata": {},
   "source": [
    "Define a variables to contain the s3url of the location that has the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe415b8-4cbb-4306-9088-17ca482ca987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model will be uploaded to ---- > s3://sagemaker-us-east-1-576219157147/qwen_2/\n"
     ]
    }
   ],
   "source": [
    "s3_model_prefix = \"qwen_2\"  # folder within bucket where code artifact will go\n",
    "jinja_env = jinja2.Environment()\n",
    "pretrained_model_location = f\"s3://{model_bucket}/{s3_model_prefix}/\"\n",
    "print(f\"Pretrained model will be uploaded to ---- > {pretrained_model_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aec73f-6dc9-46a0-b2fa-24750fa6bdd9",
   "metadata": {},
   "source": [
    "Get the inference container image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e56ce5a-8b00-4f45-8beb-4231f3b34ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.25.0-deepspeed0.11.0-cu118'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\", region=sess.boto_session.region_name, version=\"0.25.0\"\n",
    ")\n",
    "inference_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee71b98-cb62-4050-8493-da242dfd0ce9",
   "metadata": {},
   "source": [
    "Setup model name variables and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748c183d-6d9f-4502-bdda-5851e2f03471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"Qwen/Qwen2-0.5B-Chat\"\n",
    "model_names = {\n",
    "    \"model_name\": model_version, #@param [\"Qwen/Qwen-VL\", \"Qwen/Qwen-VL-Chat\", \"Qwen/Qwen-VL-Chat-Int4\"]\n",
    "}\n",
    "with open(\"inference-artifacts/model_name.json\",'w') as file:\n",
    "    json.dump(model_names, file)\n",
    "\n",
    "with open(\"inference-artifacts/serving.properties\", 'r') as f:\n",
    "    current = f.read()\n",
    "\n",
    "with open(\"inference-artifacts/serving.properties\", 'w') as f:\n",
    "    updated = current.replace(\"SAGEMAKER_BUCKET\", model_bucket)\n",
    "    f.write(updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd09053-0aeb-47a2-9b36-336b4d15e3b6",
   "metadata": {},
   "source": [
    "Create compressed file for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c013416-2127-42e9-b557-86c5aa17ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference-artifacts/\n",
      "inference-artifacts/model.py\n",
      "inference-artifacts/requirements.txt\n",
      "inference-artifacts/serving.properties\n",
      "inference-artifacts/model_name.json\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "rm -r inference-artifacts/.ipynb_checkpoints\n",
    "tar czvf model.tar.gz inference-artifacts/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63ff2e-5703-4c78-adaa-26af2019cf68",
   "metadata": {},
   "source": [
    "Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47ab9fa-53f6-4bd0-864c-25a6811ccf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-576219157147/qwen_2/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", model_bucket, s3_model_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57450a48-4dcc-435c-a379-9926f44fc142",
   "metadata": {},
   "source": [
    "Set endpoint name and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a366911-ddc1-4027-9a5e-d2af5740f863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qwen2-0-5B-Chat-2024-06-06-19-36-29-157'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "model_name = name_from_base(model_version).split('/')[-1].replace(\".\",\"-\")\n",
    "model = Model(\n",
    "    image_uri=inference_image_uri,\n",
    "    model_data=s3_code_artifact,\n",
    "    role=role,\n",
    "    name=model_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "686b664b-b197-42ec-bea4-54919cea388c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!CPU times: user 80.9 ms, sys: 24.3 ms, total: 105 ms\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "endpoint_name = \"endpoint-\" + model_name\n",
    "print(f\"Deploying {endpoint_name}\")\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043916d-448d-45a2-a6af-07f798209260",
   "metadata": {},
   "source": [
    "## Test deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097de01e-6c61-4f11-ad5e-66a82516ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model is an artificial intelligence system that can generate human-like text by analyzing large amounts of natural language data. These models are typically trained on vast amounts of text data, which includes documents, news articles, and social media posts, among other sources. The goal of these models is to produce text that is coherent, grammatically correct, and informative, with the ability to generate new ideas and concepts based on context and patterns in the input data.\n",
      "\n",
      "Large language models have been used in a variety of applications, including chatbots, virtual assistants, natural language processing (NLP), and knowledge representation systems. They have also been used to train machine learning models for tasks such as speech recognition, image classification, and recommendation systems. Large language models are becoming increasingly important in many industries, particularly those involving complex reasoning, decision-making, and creativity.\n"
     ]
    }
   ],
   "source": [
    "sagemaker_runtime = boto3.client(\n",
    "    \"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    Body=bytes('{\"prompt\": \"Give me a short introduction to large language model.\"}', 'utf-8')\n",
    "    )\n",
    "\n",
    "# Decodes and prints the response body:\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e14950-9436-487b-956a-894772091770",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf4012-f794-4015-a602-b13e14f89a8c",
   "metadata": {},
   "source": [
    "Real-time inference - Amazon SageMaker - https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
